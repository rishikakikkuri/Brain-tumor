{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nibabel as nib\nimport matplotlib.pyplot as plt\n\nimport json\nimport cv2\nimport h5py\nimport imageio\nfrom IPython.display import Image\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K \nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import (\n    Activation,\n    Conv3D,\n    Conv3DTranspose,\n    MaxPooling3D,\n    UpSampling3D,\n)\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\n\n#from tensorflow.compat.v1.logging import INFO, set_verbosity\n\n#set_verbosity(INFO)\n\nK.set_image_data_format(\"channels_first\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set home directory and data directory\nHOME_DIR = \"./BraTS-Data/\"\nDATA_DIR = HOME_DIR","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_nifty_file = DATA_DIR + \"imagesTr/BRATS_003.nii.gz\"\nimage = np.array(nib.load(image_nifty_file).get_fdata())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_nifty_file = DATA_DIR + \"labelsTr/BRATS_003.nii.gz\"\nlabel = np.array(nib.load(label_nifty_file).get_fdata())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"is_categorical=False\nif not is_categorical:\n    label_cat = to_categorical(label, num_classes=4).astype(np.uint8)\nlabel_cat.shape\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_norm = cv2.normalize(image[:, :, :, 0], None, alpha=0, beta=255,\n                      norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F).astype(np.uint8)\nimage_norm.shape\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labeled_image = np.zeros_like(label_cat[:, :, :, 1:])\n\n# remove tumor part from image\nlabeled_image[:, :, :, 0] = image_norm * (label_cat[:, :, :, 0])\nlabeled_image[:, :, :, 1] = image_norm * (label_cat[:, :, :, 0])\nlabeled_image[:, :, :, 2] = image_norm * (label_cat[:, :, :, 0])\n\n# color labels\nlabeled_image += label_cat[:, :, :, 1:] * 255\n\nlabeled_image.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_all = []\ndata_all.append(labeled_image)\nnp.array(data_all).shape\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coronal = np.transpose(data_all, [1, 3, 2, 4, 0])\ncoronal = np.rot90(coronal, 1)\ncoronal.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transversal = np.transpose(data_all, [2, 1, 3, 4, 0])\ntransversal = np.rot90(transversal, 2)\ntransversal.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sagittal = np.transpose(data_all, [2, 3, 1, 4, 0])\nsagittal = np.rot90(sagittal, 1)\nsagittal.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(3, 6, figsize=[16, 9])\n\nfor i in range(6):\n    n = np.random.randint(coronal.shape[2])\n    ax[0][i].imshow(np.squeeze(coronal[:, :, n, :]))\n    ax[0][i].set_xticks([])\n    ax[0][i].set_yticks([])\n    if i == 0:\n        ax[0][i].set_ylabel('Coronal', fontsize=15)\n\nfor i in range(6):\n    n = np.random.randint(transversal.shape[2])\n    ax[1][i].imshow(np.squeeze(transversal[:, :, n, :]))\n    ax[1][i].set_xticks([])\n    ax[1][i].set_yticks([])\n    if i == 0:\n        ax[1][i].set_ylabel('Transversal', fontsize=15)\n\nfor i in range(6):\n    n = np.random.randint(sagittal.shape[2])\n    ax[2][i].imshow(np.squeeze(sagittal[:, :, n, :]))\n    ax[2][i].set_xticks([])\n    ax[2][i].set_yticks([])\n    if i == 0:\n        ax[2][i].set_ylabel('Sagittal', fontsize=15)\n\nfig.subplots_adjust(wspace=0, hspace=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_data_gif(data_):\n    images = []\n    for i in range(data_.shape[0]):\n        x = data_[min(i, data_.shape[0] - 1), :, :]\n        y = data_[:, min(i, data_.shape[1] - 1), :]\n        z = data_[:, :, min(i, data_.shape[2] - 1)]\n        img = np.concatenate((x, y, z), axis=1)\n        images.append(img)\n    imageio.mimsave(\"./gif.gif\", images, duration=0.01)\n    return Image(filename=\"./gif.gif\", format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_data_gif(labeled_image)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sub_volume(image, label, \n                   orig_x = 240, orig_y = 240, orig_z = 155, \n                   output_x = 160, output_y = 160, output_z = 16,\n                   num_classes = 4, max_tries = 1000, \n                   background_threshold=0.95):\n    \"\"\"\n    Extract random sub-volume from original images.\n\n    Args:\n        image (np.array): original image, \n            of shape (orig_x, orig_y, orig_z, num_channels)\n        label (np.array): original label. \n            labels coded using discrete values rather than\n            a separate dimension, \n            so this is of shape (orig_x, orig_y, orig_z)\n        orig_x (int): x_dim of input image\n        orig_y (int): y_dim of input image\n        orig_z (int): z_dim of input image\n        output_x (int): desired x_dim of output\n        output_y (int): desired y_dim of output\n        output_z (int): desired z_dim of output\n        num_classes (int): number of class labels\n        max_tries (int): maximum trials to do when sampling\n        background_threshold (float): limit on the fraction \n            of the sample which can be the background\n            returns:\n        X (np.array): sample of original image of dimension \n            (num_channels, output_x, output_y, output_z)\n        y (np.array): labels which correspond to X, of dimension \n            (num_classes, output_x, output_y, output_z)\n    \"\"\"\n    # Initialize features and labels with `None`\n    X = None\n    y = None\n\n    tries = 0    \n    while tries < max_tries:\n        # randomly sample sub-volume by sampling the corner voxel\n        # hint: make sure to leave enough room for the output dimensions!\n        start_x = np.random.randint(0, orig_x - output_x+1)\n        start_y = np.random.randint(0, orig_y - output_y+1)\n        start_z = np.random.randint(0, orig_z - output_z+1)\n\n        # extract relevant area of label\n        y = label[start_x: start_x + output_x,\n                  start_y: start_y + output_y,\n                  start_z: start_z + output_z]\n         y = keras.utils.to_categorical(y, num_classes=num_classes)\n\n        # compute the background ratio\n        bgrd_ratio = np.sum(y[:, :, :, 0])/(output_x * output_y * output_z)\n\n        # increment tries counter\n        tries += 1\n\n        # if background ratio is below the desired threshold,\n        # use that sub-volume.\n        # otherwise continue the loop and try another random sub-volume\n        if bgrd_ratio < background_threshold:\n\n            # make copy of the sub-volume\n            X = np.copy(image[start_x: start_x + output_x,\n                              start_y: start_y + output_y,\n                              start_z: start_z + output_z, :])\n            \n            # change dimension of X\n            # from (x_dim, y_dim, z_dim, num_channels)\n            # to (num_channels, x_dim, y_dim, z_dim)\n            X = np.moveaxis(X, 3, 0)\n\n            # change dimension of y\n            # from (x_dim, y_dim, z_dim, num_classes)\n            # to (num_classes, x_dim, y_dim, z_dim)\n            y = np.moveaxis(y, 3, 0)\n\n            # take a subset of y that excludes the background class\n            # in the 'num_classes' dimension\n            y = y[1:, :, :, :]\n    \n            return X, y\n\n    # if we've tried max_tries number of samples\n    # Give up in order to avoid looping forever.\n    print(f\"Tried {tries} times to find a sub-volume. Giving up...\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(3)\n\nimage = np.zeros((4, 4, 3, 1))\nlabel = np.zeros((4, 4, 3))\nfor i in range(4):\n    for j in range(4):\n        for k in range(3):\n            image[i, j, k, 0] = i*j*k\n            label[i, j, k] = k\n\nprint(\"image:\")\nfor k in range(3):\n    print(f\"z = {k}\")\n    print(image[:, :, k, 0])\nprint(\"\\n\")\nprint(\"label:\")\nfor k in range(3):\n    print(f\"z = {k}\")\n    print(label[:, :, k])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_image, sample_label = get_sub_volume(image, \n                                            label,\n                                            orig_x=4, \n                                            orig_y=4, \n                                            orig_z=3,\n                                            output_x=2, \n                                            output_y=2, \n                                            output_z=2,\n                                            num_classes = 3)\n\nprint(\"Sampled Image:\")\nfor k in range(2):\n    print(\"z = \" + str(k))\n    print(sample_image[0, :, :, k])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Sampled Label:\")\nfor c in range(2):\n    print(\"class = \" + str(c))\n    for k in range(2):\n        print(\"z = \" + str(k))\n        print(sample_label[c, :, :, k])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOME_DIR = \"./BraTS-Data/\"\nDATA_DIR = HOME_DIR\n\ndef load_case(image_nifty_file, label_nifty_file):\n    # load the image and label file, get the image content and return a numpy array for each\n    image = np.array(nib.load(image_nifty_file).get_fdata())\n    label = np.array(nib.load(label_nifty_file).get_fdata())\n    \n    return image, label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = load_case(DATA_DIR + \"imagesTr/BRATS_001.nii.gz\", DATA_DIR + \"labelsTr/BRATS_001.nii.gz\")\nX, y = get_sub_volume(image, label)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_patch(X, y):\n    fig, ax = plt.subplots(1, 2, figsize=[10, 5], squeeze=False)\n\n    ax[0][0].imshow(X[:, :, 0], cmap='Greys_r')\n    ax[0][0].set_yticks([])\n    ax[0][0].set_xticks([])\n    ax[0][1].imshow(y[:, :, 0], cmap='Greys_r')\n    ax[0][1].set_xticks([])\n    ax[0][1].set_yticks([])\n\n    fig.subplots_adjust(wspace=0, hspace=0)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_patch(X[0, :, :, :], y[2])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def standardize(image):\n    \"\"\"\n    Standardize mean and standard deviation \n        of each channel and z_dimension.\n\n    Args:\n        image (np.array): input image, \n            shape (num_channels, dim_x, dim_y, dim_z)\n\n    Returns:\n        standardized_image (np.array): standardized version of input image\n    \"\"\"\n        \n    # initialize to array of zeros, with same shape as the image\n    standardized_image = np.zeros(image.shape)\n\n    # iterate over channels\n    for c in range(image.shape[0]):\n        # iterate over the `z` dimension\n        for z in range(image.shape[3]):\n            # get a slice of the image \n            # at channel c and z-th dimension `z`\n            image_slice = image[c,:,:,z]\n\n            # subtract the mean\n            centered = image_slice - np.mean(image_slice)\n\n            # divide by the standard deviation\n            if np.std(centered) != 0:\n                centered_scaled = centered / np.std(centered)\n                # update  the slice of standardized image\n            # with the scaled centered and scaled image\n            standardized_image[c, :, :, z] = centered_scaled\n\n\n    return standardized_image\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_norm = standardize(X)\nprint(\"standard deviation for a slice should be 1.0\")\nprint(f\"stddv for X_norm[0, :, :, 0]: {X_norm[0,:,:,0].std():.2f}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_patch(X_norm[0, :, :, :], y[2])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def single_class_dice_coefficient(y_true, y_pred, axis=(0, 1, 2), \n                                  epsilon=0.00001):\n    \"\"\"\n    Compute dice coefficient for single class.\n\n    Args:\n        y_true (Tensorflow tensor): tensor of ground truth values for single class.\n                                    shape: (x_dim, y_dim, z_dim)\n        y_pred (Tensorflow tensor): tensor of predictions for single class.\n                                    shape: (x_dim, y_dim, z_dim)\n        axis (tuple): spatial axes to sum over when computing numerator and\n                      denominator of dice coefficient.\n                      Hint: pass this as the 'axis' argument to the K.sum function.\n        epsilon (float): small constant added to numerator and denominator to\n                        avoid divide by 0 errors.\n    Returns:\n        dice_coefficient (float): computed value of dice coefficient.     \n    \"\"\"\n\n    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n    dice_denominator = K.sum(y_true, axis=axis) + K.sum(y_pred, axis=axis) + epsilon\n    dice_coefficient = (dice_numerator) / (dice_denominator)\n\n    return dice_coefficient","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.expand_dims(np.eye(2), -1)\nlabel = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\n\nprint(\"Test Case #1\")\nprint(\"pred:\")\nprint(pred[:, :, 0])\nprint(\"label:\")\nprint(label[:, :, 0])\n\n# choosing a large epsilon to help check for implementation errors\ndc = single_class_dice_coefficient(pred, label,epsilon=1)\nprint(f\"dice coefficient: {dc.numpy():.4f}\")\n\nprint(\"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test Case #2\")\npred = np.expand_dims(np.eye(2), -1)\nlabel = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n\nprint(\"pred:\")\nprint(pred[:, :, 0])\nprint(\"label:\")\nprint(label[:, :, 0])\n\n# choosing a large epsilon to help check for implementation errors\ndc = single_class_dice_coefficient(pred, label,epsilon=1)\nprint(f\"dice_coefficient: {dc.numpy():.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_coefficient(y_true, y_pred, axis=(1, 2, 3), \n                     epsilon=0.00001):\n    \"\"\"\n    Compute mean dice coefficient over all abnormality classes.\n\n    Args:\n        y_true (Tensorflow tensor): tensor of ground truth values for all classes.\n                                    shape: (num_classes, x_dim, y_dim, z_dim)\n        y_pred (Tensorflow tensor): tensor of predictions for all classes.\n                                    shape: (num_classes, x_dim, y_dim, z_dim)\n        axis (tuple): spatial axes to sum over when computing numerator and\n                      denominator of dice coefficient.\n                      Hint: pass this as the 'axis' argument to the K.sum\n                            and K.mean functions.\n        epsilon (float): small constant add to numerator and denominator to\n                        avoid divide by 0 errors.\n    Returns:\n        dice_coefficient (float): computed value of dice coefficient.     \n    \"\"\"\n\n    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n    dice_denominator = K.sum(y_true, axis=axis) + K.sum(y_pred, axis=axis) + epsilon\n    dice_coefficient = K.mean((dice_numerator)/(dice_denominator))\n \n    return dice_coefficient","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n\nprint(\"Test Case #1\")\nprint(\"pred:\")\nprint(pred[0, :, :, 0])\nprint(\"label:\")\nprint(label[0, :, :, 0])\n\ndc = dice_coefficient(label, pred, epsilon=1)\nprint(f\"dice coefficient: {dc.numpy():.4f}\")\n\nprint(\"\\n\")\n\nprint(\"Test Case #2\")\npred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n\n\nprint(\"pred:\")\nprint(pred[0, :, :, 0])\nprint(\"label:\")\nprint(label[0, :, :, 0])\n\ndc = dice_coefficient(pred, label,epsilon=1)\nprint(f\"dice coefficient: {dc.numpy():.4f}\")\nprint(\"\\n\")\nprint(\"Test Case #3\")\npred = np.zeros((2, 2, 2, 1))\npred[0, :, :, :] = np.expand_dims(np.eye(2), -1)\npred[1, :, :, :] = np.expand_dims(np.eye(2), -1)\n\nlabel = np.zeros((2, 2, 2, 1))\nlabel[0, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\nlabel[1, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n\nprint(\"pred:\")\nprint(\"class = 0\")\nprint(pred[0, :, :, 0])\nprint(\"class = 1\")\nprint(pred[1, :, :, 0])\nprint(\"label:\")\nprint(\"class = 0\")\nprint(label[0, :, :, 0])\nprint(\"class = 1\")\nprint(label[1, :, :, 0])\n\ndc = dice_coefficient(pred, label,epsilon=1)\nprint(f\"dice coefficient: {dc.numpy():.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), \n                   epsilon=0.00001):\n    \"\"\"\n    Compute mean soft dice loss over all abnormality classes.\n\n    Args:\n        y_true (Tensorflow tensor): tensor of ground truth values for all classes.\n                                    shape: (num_classes, x_dim, y_dim, z_dim)\n        y_pred (Tensorflow tensor): tensor of soft predictions for all classes.\n                                    shape: (num_classes, x_dim, y_dim, z_dim)\n        axis (tuple): spatial axes to sum over when computing numerator and\n                      denominator in formula for dice loss.\n                      Hint: pass this as the 'axis' argument to the K.sum\n                            and K.mean functions.\n        epsilon (float): small constant added to numerator and denominator to\n                        avoid divide by 0 errors.\n    Returns:\n        dice_loss (float): computed value of dice loss.     \n    \"\"\"\n\n    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n    dice_denominator = K.sum(y_true**2, axis=axis) + K.sum(y_pred**2, axis=axis) + epsilon\n    dice_loss = 1 - K.mean((dice_numerator)/(dice_denominator))\n\n    return dice_loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n\nprint(\"Test Case #1\")\nprint(\"pred:\")\nprint(pred[0, :, :, 0])\nprint(\"label:\")\nprint(label[0, :, :, 0])\n\ndc = soft_dice_loss(pred, label, epsilon=1)\nprint(f\"soft dice loss:{dc.numpy():.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n\nprint(\"Test Case #2\")\npred = np.expand_dims(np.expand_dims(0.5*np.eye(2), 0), -1)\nprint(\"pred:\")\nprint(pred[0, :, :, 0])\nprint(\"label:\")\nprint(label[0, :, :, 0])\ndc = soft_dice_loss(pred, label, epsilon=1)\nprint(f\"soft dice loss: {dc.numpy():.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n\nprint(\"Test Case #3\")\npred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n\nprint(\"pred:\")\nprint(pred[0, :, :, 0])\nprint(\"label:\")\nprint(label[0, :, :, 0])\n\ndc = soft_dice_loss(pred, label, epsilon=1)\nprint(f\"soft dice loss: {dc.numpy():.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n\nprint(\"Test Case #4\")\npred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\npred[0, 0, 1, 0] = 0.8\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n\nprint(\"pred:\")\nprint(pred[0, :, :, 0])\nprint(\"label:\")\nprint(label[0, :, :, 0])\n\ndc = soft_dice_loss(pred, label, epsilon=1)\nprint(f\"soft dice loss: {dc.numpy():.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n\nprint(\"Test Case #5\")\npred = np.zeros((2, 2, 2, 1))\npred[0, :, :, :] = np.expand_dims(0.5*np.eye(2), -1)\npred[1, :, :, :] = np.expand_dims(np.eye(2), -1)\npred[1, 0, 1, 0] = 0.8\n\nlabel = np.zeros((2, 2, 2, 1))\nlabel[0, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\nlabel[1, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n\nprint(\"pred:\")\nprint(\"class = 0\")\nprint(pred[0, :, :, 0])\nprint(\"class = 1\")\nprint(pred[1, :, :, 0])\nprint(\"label:\")\nprint(\"class = 0\")\nprint(label[0, :, :, 0])\nprint(\"class = 1\")\nprint(label[1, :, :, 0])\n\ndc = soft_dice_loss(pred, label, epsilon=1)\nprint(f\"soft dice loss: {dc.numpy():.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.array([\n                    [\n                        [ \n                            [1.0, 1.0], [0.0, 0.0]\n                        ],\n                        [\n                            [1.0, 0.0], [0.0, 1.0]\n                        ]\n                    ],\n                    [\n                        [ \n                            [1.0, 1.0], [0.0, 0.0]\n                        ],\n                        [\n                            [1.0, 0.0], [0.0, 1.0]\n                        ]\n                    ],\n                  ])\nlabel = np.array([\n                    [\n                        [ \n                            [1.0, 0.0], [1.0, 0.0]\n                        ],\n                        [\n                            [1.0, 0.0], [0.0, 0.0]\n                        ]\n                    ],\n                    [\n                        [ \n                            [0.0, 0.0], [0.0, 0.0]\n                        ],\n                        [\n                            [1.0, 0.0], [0.0, 0.0]\n                        ]\n                    ]\n                  ])\nprint(\"Test case #6\")\ndc = soft_dice_loss(pred, label, epsilon=1)\nprint(f\"soft dice loss\",dc.numpy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_convolution_block(input_layer, n_filters, batch_normalization=False,\n                             kernel=(3, 3, 3), activation=None,\n                             padding='same', strides=(1, 1, 1),\n                             instance_normalization=False):\n    \"\"\"\n    :param strides:\n    :param input_layer:\n    :param n_filters:\n    :param batch_normalization:\n    :param kernel:\n    :param activation: Keras activation layer to use. (default is 'relu')\n    :param padding:\n    :return:\n    \"\"\"\n    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(\n        input_layer)\n    if activation is None:\n        return Activation('relu')(layer)\n    else:\n        return activation()(layer)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2),\n                       strides=(2, 2, 2),\n                       deconvolution=False):\n    if deconvolution:\n        return Conv3DTranspose(filters=n_filters, kernel_size=kernel_size,\n                               strides=strides)\n    else:\n        return UpSampling3D(size=pool_size)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"                  pool_size=(2, 2, 2), n_labels=3,\n                  initial_learning_rate=0.00001,\n                  deconvolution=False, depth=4, n_base_filters=32,\n                  include_label_wise_dice_coefficients=False, metrics=[],\n                  batch_normalization=False, activation_name=\"sigmoid\"):\n    \"\"\"\n    Builds the 3D UNet Keras model.f\n    :param metrics: List metrics to be calculated during model training (default is dice coefficient).\n    :param include_label_wise_dice_coefficients: If True and n_labels is greater than 1, model will report the dice\n    coefficient for each label as metric.\n    :param n_base_filters: The number of filters that the first layer in the convolution network will have. Following\n    layers will contain a multiple of this number. Lowering this number will likely reduce the amount of memory required\n    to train the model.\n    :param depth: indicates the depth of the U-shape for the model. The greater the depth, the more max pooling\n    layers will be added to the model. Lowering the depth may reduce the amount of memory required for training.\n    :param input_shape: Shape of the input data (n_chanels, x_size, y_size, z_size). The x, y, and z sizes must be\n    divisible by the pool size to the power of the depth of the UNet, that is pool_size^depth.\n    :param pool_size: Pool size for the max pooling operations.\n    :param n_labels: Number of binary labels that the model is learning.\n    :param initial_learning_rate: Initial learning rate for the model. This will be decayed during training.\n    :param deconvolution: If set to True, will use transpose convolution(deconvolution) instead of up-sampling. This\n    increases the amount memory required during training.\n    :return: Untrained 3D UNet Model\n    \"\"\"\n    inputs = Input(input_shape)\n    current_layer = inputs\n    levels = list()\n    for layer_depth in range(depth):\n        layer1 = create_convolution_block(input_layer=current_layer,\n                                          n_filters=n_base_filters * (\n                                                  2 ** layer_depth),\n                                          batch_normalization=batch_normalization)\n        layer2 = create_convolution_block(input_layer=layer1,\n                                          n_filters=n_base_filters * (\n                                                  2 ** layer_depth) * 2,\n                                          batch_normalization=batch_normalization)\n        if layer_depth < depth - 1:\n            current_layer = MaxPooling3D(pool_size=pool_size)(layer2)\n            levels.append([layer1, layer2, current_layer])\n        else:\n            current_layer = layer2\n            levels.append([layer1, layer2])\n\n    # add levels with up-convolution or up-sampling\n    for layer_depth in range(depth - 2, -1, -1):\n        \n        #print(K.int_shape(current_layer)[1])\n        up_convolution = get_up_convolution(pool_size=pool_size,\n                                            deconvolution=deconvolution,\n                                            n_filters=K.int_shape(current_layer)[1])(current_layer)\n        \n        concat = concatenate([up_convolution, levels[layer_depth][1]], axis=1)\n        \n        #print(K.int_shape(levels[layer_depth][1])[1])\n        current_layer = create_convolution_block(n_filters= K.int_shape(levels[layer_depth][1])[1],\n                                                 input_layer=concat, \n                                                 batch_normalization=batch_normalization)\n        \n        current_layer = create_convolution_block(n_filters= K.int_shape(levels[layer_depth][1])[1],\n                                                 input_layer=current_layer,\n                                                 batch_normalization=batch_normalization)\n  final_convolution = Conv3D(n_labels, (1, 1, 1))(current_layer)\n    act = Activation(activation_name)(final_convolution)\n    model = Model(inputs=inputs, outputs=act)\n\n    if not isinstance(metrics, list):\n        metrics = [metrics]\n\n    model.compile(optimizer=Adam(lr=initial_learning_rate), loss=loss_function,\n                  metrics=metrics)\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(model, to_file='U-Net_Model.png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dir = HOME_DIR + \"processed/\"\n\nwith open(base_dir + \"config.json\") as json_file:\n    config = json.load(json_file)\n\nconfig","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(config[\"train\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_channels = 4\nnum_classes = 3\ndim = (160,160,16)\nX_train = np.zeros((len(config[\"train\"]), num_channels, *dim),\n             dtype=np.float64)\ny_train = np.zeros((len(config[\"train\"]), num_classes, *dim),\n             dtype=np.float64)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dir = HOME_DIR + \"processed/\"\ndirectory_train = base_dir + \"train/\"\nprint(directory_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,ID in enumerate(config[\"train\"]):\n    # Store sample\n    with h5py.File(directory_train + ID, 'r') as f:\n        X_train[i] = np.array(f.get(\"x\"))\n        # remove the background class\n        y_train[i] = np.moveaxis(np.array(f.get(\"y\")), 3, 0)[1:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(config[\"valid\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialization\nnum_channels = 4\nnum_classes = 3\ndim = (160,160,16)\nX_valid = np.zeros((len(config[\"valid\"]), num_channels, *dim),\n             dtype=np.float64)\ny_valid = np.zeros((len(config[\"valid\"]), num_classes, *dim),\n             dtype=np.float64)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate data\nbase_dir = HOME_DIR + \"processed/\"\ndirectory_valid = base_dir + \"valid/\"\nprint(directory_valid)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,ID in enumerate(config[\"valid\"]):\n    # Store sample\n    with h5py.File(directory_valid + ID, 'r') as f:\n        X_valid[i] = np.array(f.get(\"x\"))\n        # remove the background class\n        y_valid[i] = np.moveaxis(np.array(f.get(\"y\")), 3, 0)[1:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs=2\nmodel.fit(X_train,y_train,\n        epochs=n_epochs,\n        #use_multiprocessing=True,\n        validation_data= (X_valid,y_valid),\n        verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VolumeDataGenerator(tf.keras.utils.Sequence):\n    def __init__(self,\n                sample_list,\n                 base_dir,\n                 batch_size=1,\n                 shuffle=True,\n                 dim=(160, 160, 16),\n                 num_channels=4,\n                 num_classes=3,\n                 verbose=1):\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.base_dir = base_dir\n        self.dim = dim\n        self.num_channels = num_channels\n        self.num_classes = num_classes\n        self.verbose = verbose\n        self.sample_list = sample_list\n        self.on_epoch_end()\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.sample_list))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.sample_list) / self.batch_size))\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.zeros((self.batch_size, self.num_channels, *self.dim),\n                     dtype=np.float64)\n        y = np.zeros((self.batch_size, self.num_classes, *self.dim),\n                     dtype=np.float64)\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            if self.verbose == 1:\n                print(\"Training on: %s\" % self.base_dir + ID)\n            with h5py.File(self.base_dir + ID, 'r') as f:\n                X[i] = np.array(f.get(\"x\"))\n                # remove the background class\n                y[i] = np.moveaxis(np.array(f.get(\"y\")), 3, 0)[1:]\n        return X, y\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[\n                  index * self.batch_size: (index + 1) * self.batch_size]\n        # Find list of IDs\n        sample_list_temp = [self.sample_list[k] for k in indexes]\n        # Generate data\n        X, y = self.__data_generation(sample_list_temp)\n        return X, y\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = VolumeDataGenerator(config[\"train\"], base_dir + \"train/\", batch_size=1, dim=(160, 160, 16), verbose=0)\nvalid_generator = VolumeDataGenerator(config[\"valid\"], base_dir + \"valid/\", batch_size=1, dim=(160, 160, 16), verbose=0)\ntrain_generator","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs=10\n#validation_steps = 10\n\nmodel.fit(train_generator,\n        #steps_per_epoch=steps_per_epoch,\n        epochs=n_epochs,\n        #use_multiprocessing=True,\n        validation_data=valid_generator,\n        #validation_steps=validation_steps,\n         verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run this cell if you to save the weights of your trained model in cell above\nmodel.save_weights(HOME_DIR + 'my_model_pretrained.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOME_DIR = \"./BraTS-Data/\"\nmodel.load_weights(HOME_DIR + \"my_model_pretrained.hdf5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_loss, val_dice = model.evaluate(valid_generator)\n\nprint(f\"validation soft dice loss: {val_loss:.4f}\")\nprint(f\"validation dice coefficient: {val_dice:.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_norm_with_batch_dimension = np.expand_dims(X_norm, axis=0)\npatch_pred = model.predict(X_norm_with_batch_dimension)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set threshold.\nthreshold = 0.5\n\n# use threshold to get hard predictions\npatch_pred[patch_pred > threshold] = 1.0\npatch_pred[patch_pred <= threshold] = 0.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Patch and ground truth\")\nvisualize_patch(X_norm[0, :, :, :], y[2])\nplt.show()\nprint(\"Patch and prediction\")\nvisualize_patch(X_norm[0, :, :, :], patch_pred[0, 2, :, :, :])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_class_sens_spec(pred, label, class_num):\n    \"\"\"\n    Compute sensitivity and specificity for a particular example\n    for a given class.\n\n    Args:\n        pred (np.array): binary arrary of predictions, shape is\n                         (num classes, height, width, depth).\n        label (np.array): binary array of labels, shape is\n                          (num classes, height, width, depth).\n        class_num (int): number between 0 - (num_classes -1) which says\n                         which prediction class to compute statistics\n                         for.\n\n    Returns:\n        sensitivity (float): precision for given class_num.\n        specificity (float): recall for given class_num\n    \"\"\"\n\n    # extract sub-array for specified class\n    class_pred = pred[class_num]\n    class_label = label[class_num]\n\n    # compute:\n    \n    # true positives\n    tp = np.sum((class_pred == 1) & (class_label == 1))\n\n    # true negatives\n    tn = np.sum((class_pred == 0) & (class_label == 0))\n     #false positives\n    fp = np.sum((class_pred == 1) & (class_label == 0))\n    \n    # false negatives\n    fn = np.sum((class_pred == 0) & (class_label == 1))\n\n    # compute sensitivity and specificity\n    sensitivity = tp / (tp + fn)\n    specificity = tn / (tn + fp)\n\n    return sensitivity, specificity","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n\nprint(\"Test Case #1\")\nprint(\"pred:\")\nprint(pred[0, :, :, 0])\nprint(\"label:\")\nprint(label[0, :, :, 0])\n\nsensitivity, specificity = compute_class_sens_spec(pred, label, 0)\nprint(f\"sensitivity: {sensitivity:.4f}\")\nprint(f\"specificity: {specificity:.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test Case #2\")\n\npred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\nlabel = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n\nprint(\"pred:\")\nprint(pred[0, :, :, 0])\nprint(\"label:\")\nprint(label[0, :, :, 0])\n\nsensitivity, specificity = compute_class_sens_spec(pred, label, 0)\nprint(f\"sensitivity: {sensitivity:.4f}\")\nprint(f\"specificity: {specificity:.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Even though we could use this function without importing it, keep this import in order to allow the grader to work\nfrom IPython.display import display\nprint(\"Test Case #3\")\n\ndf = pd.DataFrame({'y_test': [1,1,0,0,0,0,0,0,0,1,1,1,1,1],\n                   'preds_test': [1,1,0,0,0,1,1,1,1,0,0,0,0,0],\n                   'category': ['TP','TP','TN','TN','TN','FP','FP','FP','FP','FN','FN','FN','FN','FN']\n                  })\n\ndisplay(df)\npred = np.array( [df['preds_test']])\nlabel = np.array( [df['y_test']])\n\nsensitivity, specificity = compute_class_sens_spec(pred, label, 0)\nprint(f\"sensitivity: {sensitivity:.4f}\")\nprint(f\"specificity: {specificity:.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sensitivity, specificity = compute_class_sens_spec(patch_pred[0], y, 2)\n\nprint(f\"Sensitivity: {sensitivity:.4f}\")\nprint(f\"Specificity: {specificity:.4f}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sens_spec_df(pred, label):\n    patch_metrics = pd.DataFrame(\n        columns = ['Edema', \n                   'Non-Enhancing Tumor', \n                   'Enhancing Tumor'], \n        index = ['Sensitivity',\n                 'Specificity'])\n    \n    for i, class_name in enumerate(patch_metrics.columns):\n        sens, spec = compute_class_sens_spec(pred, label, i)\n        patch_metrics.loc['Sensitivity', class_name] = round(sens,4)\n        patch_metrics.loc['Specificity', class_name] = round(spec,4)\n\n    return patch_metrics","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = get_sens_spec_df(patch_pred[0], y)\n\nprint(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_labeled_image(image, label, is_categorical=False):\n    if not is_categorical:\n        label = to_categorical(label, num_classes=4).astype(np.uint8)\n\n    image = cv2.normalize(image[:, :, :, 0], None, alpha=0, beta=255,\n                          norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F).astype(\n        np.uint8)\n\n    labeled_image = np.zeros_like(label[:, :, :, 1:])\n\n    # remove tumor part from image\n    labeled_image[:, :, :, 0] = image * (label[:, :, :, 0])\n    labeled_image[:, :, :, 1] = image * (label[:, :, :, 0])\n    labeled_image[:, :, :, 2] = image * (label[:, :, :, 0])\n\n    # color labels\n    labeled_image += label[:, :, :, 1:] * 255\n    return labeled_image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_and_viz(image, label, model, threshold, loc=(100, 100, 50)):\n    image_labeled = get_labeled_image(image.copy(), label.copy())\n\n    model_label = np.zeros([3, 320, 320, 160])\n\n    for x in range(0, image.shape[0], 160):\n        for y in range(0, image.shape[1], 160):\n            for z in range(0, image.shape[2], 16):\n                patch = np.zeros([4, 160, 160, 16])\n                p = np.moveaxis(image[x: x + 160, y: y + 160, z:z + 16], 3, 0)\n                patch[:, 0:p.shape[1], 0:p.shape[2], 0:p.shape[3]] = p\n                pred = model.predict(np.expand_dims(patch, 0))\n                model_label[:, x:x + p.shape[1],\n                y:y + p.shape[2],\n                z: z + p.shape[3]] += pred[0][:, :p.shape[1], :p.shape[2],\n                                      :p.shape[3]]\n\n    model_label = np.moveaxis(model_label[:, 0:240, 0:240, 0:155], 0, 3)\n    model_label_reformatted = np.zeros((240, 240, 155, 4))\n\n    model_label_reformatted = to_categorical(label, num_classes=4).astype(\n        np.uint8)\n\n    model_label_reformatted[:, :, :, 1:4] = model_label\n\n    model_labeled_image = get_labeled_image(image, model_label_reformatted,\n                                            is_categorical=True)\n\n    fig, ax = plt.subplots(2, 3, figsize=[10, 7])\n\n    # plane values\n    x, y, z = loc\n    ax[0][0].imshow(np.rot90(image_labeled[x, :, :, :]))\n    ax[0][0].set_ylabel('Ground Truth', fontsize=15)\n    ax[0][0].set_xlabel('Sagital', fontsize=15)\n\n    ax[0][1].imshow(np.rot90(image_labeled[:, y, :, :]))\n    ax[0][1].set_xlabel('Coronal', fontsize=15)\n\n    ax[0][2].imshow(np.squeeze(image_labeled[:, :, z, :]))\n    ax[0][2].set_xlabel('Transversal', fontsize=15)\n\n    ax[1][0].imshow(np.rot90(model_labeled_image[x, :, :, :]))\n    ax[1][0].set_ylabel('Prediction', fontsize=15)\n\n    ax[1][1].imshow(np.rot90(model_labeled_image[:, y, :, :]))\n    ax[1][2].imshow(model_labeled_image[:, :, z, :])\n\n    fig.subplots_adjust(wspace=0, hspace=.12)\n\n    for i in range(2):\n        for j in range(3):\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])\n\n    return model_label_reformatted","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\npred = predict_and_viz(image, label, model, .5, loc=(130, 130, 77))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whole_scan_label = keras.utils.to_categorical(label, num_classes = 4)\nwhole_scan_pred = pred\n\n# move axis to match shape expected in functions\nwhole_scan_label = np.moveaxis(whole_scan_label, 3 ,0)[1:4]\nwhole_scan_pred = np.moveaxis(whole_scan_pred, 3, 0)[1:4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whole_scan_df = get_sens_spec_df(whole_scan_pred, whole_scan_label)\n\nprint(whole_scan_df)","metadata":{},"execution_count":null,"outputs":[]}]}